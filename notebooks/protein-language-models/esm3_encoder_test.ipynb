{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d270d6-b2d1-4462-af51-b8358478ae52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Assume the current working directory is \"HyperBind2-OpenSource\"\n",
    "project_root = os.path.abspath('/home/jupyter/HyperBind2-OpenSource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd37fa6-2909-4172-99f8-976bf7065583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported AntibodyStructureEncoder from antibody_structure_encoder: <class 'antibody_structure_encoder.AntibodyStructureEncoder'>\n"
     ]
    }
   ],
   "source": [
    "# Add the model directory to sys.path\n",
    "model_path = os.path.join(project_root, \"scripts\", \"model\")\n",
    "if model_path not in sys.path:\n",
    "    sys.path.insert(0, model_path)\n",
    "\n",
    "from antibody_structure_encoder import AntibodyStructureEncoder\n",
    "\n",
    "print(\"Imported AntibodyStructureEncoder from antibody_structure_encoder:\", AntibodyStructureEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2d6f0e-00b9-4271-a988-38defbc52b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from antibody_structure_encoder import AntibodyStructureEncoder\n",
    "from esm.sdk.api import ESMProtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854376b4-74d8-4f93-858f-b3d91699f317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded coordinates type: <class 'torch.Tensor'>\n",
      "Encoded coordinates shape: torch.Size([102, 37, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy antibody structure (ESMProtein object)\n",
    "dummy_antibody = ESMProtein()\n",
    "\n",
    "# For this example, we create dummy data.\n",
    "# In practice, you would load a real antibody structure via your parser.\n",
    "dummy_length = 100  # example protein length\n",
    "dummy_antibody.sequence = \"A\" * dummy_length  # A simple sequence of alanines\n",
    "# Create dummy coordinates with shape (1, L, 37, 3) as expected by tokenize_structure.\n",
    "dummy_antibody.coordinates = torch.randn(dummy_length, 37, 3)\n",
    "\n",
    "# Instantiate the singleton encoder.a\n",
    "encoder = AntibodyStructureEncoder(device=\"cuda\")\n",
    "# Optionally, set the encoder to evaluation mode to avoid certain training-specific branches.\n",
    "encoder.encoder.eval()\n",
    "\n",
    "# Use the encoder to encode the dummy antibody.\n",
    "try:\n",
    "    encoded_coords = encoder.encode(dummy_antibody)\n",
    "    print(\"Encoded coordinates type:\", type(encoded_coords))\n",
    "    print(\"Encoded coordinates shape:\", encoded_coords.shape)\n",
    "except Exception as e:\n",
    "    print(\"Error during encoding:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d303b32-1483-4bd9-863d-cc24bb28c6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aaf012-ca1a-4c1f-b916-551ddf6d3cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047be8b-8fc0-47c0-b33b-c5343e6a6709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314ed24-4d54-4115-a0f0-5032d8e5e1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d5e81-7059-4ca7-8ab3-f5f40eb5ea28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e31fa1-72c5-4a8e-9ab2-83a2bdfc54a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Module for encoding and ingesting antibody structure data for fine-tuning.\n",
    "\n",
    "This file includes:\n",
    "  - AntibodyStructureDataset: A PyTorch Dataset for processing PDB files.\n",
    "  - create_dataloaders: A convenience function to build training and validation DataLoaders.\n",
    "  - custom_collate_fn: A custom collate function to handle variable-length tensors.\n",
    "  \n",
    "Usage:\n",
    "  python antibody_structure_ingestion.py --pdb_dir <PDB_DIRECTORY> [--batch_size 2]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Import necessary functions and classes from the codebase.\n",
    "from esm.sdk.api import ESMProtein\n",
    "from antibody_structure_encoder import AntibodyStructureEncoder  # Import the singleton antibody encoder\n",
    "\n",
    "# Instantiate the singleton encoder once.\n",
    "# This instance will be reused throughout the application.\n",
    "encoder_instance = AntibodyStructureEncoder(device=\"cuda\")\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', '..', 'scripts', 'data_ingestion', 'antibody_structure_ingestion')))\n",
    "from pdb2esm import read_monomer_structure, read_multimer_structure, detect_and_process_structure\n",
    "\n",
    "class AntibodyStructureDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading and encoding antibody structures.\n",
    "\n",
    "    Each item is a tuple of (encoded_antibody, ground_truth_coordinates).\n",
    "    \"\"\"\n",
    "    def __init__(self, pdb_directory: str, suffix: str, encoder):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by scanning for PDB files with a given suffix.\n",
    "\n",
    "        Args:\n",
    "            pdb_directory (str): Directory containing PDB files.\n",
    "            suffix (str): File suffix to filter PDB files (e.g., \"_train.pdb\" or \"_val.pdb\").\n",
    "            encoder: An instance of AntibodyStructureEncoder (singleton) to encode an antibody.\n",
    "        \"\"\"\n",
    "        self.pdb_directory = pdb_directory\n",
    "        self.pdb_files = [\n",
    "            os.path.join(pdb_directory, f)\n",
    "            for f in os.listdir(pdb_directory) if f.endswith(suffix)\n",
    "        ]\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of PDB files found.\"\"\"\n",
    "        return len(self.pdb_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves and processes a single PDB file.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (encoded_antibody, ground_truth_coordinates)\n",
    "        \"\"\"\n",
    "        pdb_path = self.pdb_files[idx]\n",
    "        # Process the PDB file into an ESMProtein (antibody) object using the custom parser.\n",
    "        antibody = detect_and_process_structure(pdb_path)\n",
    "        if antibody is None:\n",
    "            raise ValueError(f\"Antibody processing failed for {pdb_path}\")\n",
    "        # Ground truth coordinates from the processed antibody.\n",
    "        gt_coords = antibody.coordinates\n",
    "        # Encode the antibody using the singleton encoder instance.\n",
    "        encoded_antibody = self.encoder.encode(antibody)\n",
    "        return encoded_antibody, gt_coords\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length tensors by padding them.\n",
    "    \n",
    "    Args:\n",
    "        batch (list): A list of tuples (encoded_antibody, ground_truth_coordinates).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Padded tensors for encoded antibodies and ground truth coordinates.\n",
    "    \"\"\"\n",
    "    # Unzip the batch.\n",
    "    encoded_list, coords_list = zip(*batch)\n",
    "    # Pad the list of tensors along the variable dimension (assumed dim 0).\n",
    "    padded_encoded = pad_sequence(encoded_list, batch_first=True, padding_value=0)\n",
    "    padded_coords = pad_sequence(coords_list, batch_first=True, padding_value=0)\n",
    "    return padded_encoded, padded_coords\n",
    "\n",
    "def create_dataloaders(pdb_directory: str, batch_size: int = 2):\n",
    "    \"\"\"\n",
    "    Creates DataLoaders for training and validation datasets.\n",
    "\n",
    "    Args:\n",
    "        pdb_directory (str): Directory containing PDB files.\n",
    "        batch_size (int): Batch size for DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader) for training and validation data.\n",
    "    \"\"\"\n",
    "    train_dataset = AntibodyStructureDataset(pdb_directory, \"_train.pdb\", encoder=encoder_instance)\n",
    "    val_dataset = AntibodyStructureDataset(pdb_directory, \"_val.pdb\", encoder=encoder_instance)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87eeac4d-ed9b-4bb0-9f44-fab14d2e1bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdb_directory='/home/jupyter/DATA/hyperbind_train/sabdab/all_structures/train-test-split/'\n",
    "train_loader, val_loader = create_dataloaders(pdb_directory, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0c3ee50-4f67-428e-8805-f57a81c66ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detected 2 chains (['K', 'L']). Processing as a multimer.\n",
      "✅ Detected 2 chains (['H', 'L']). Processing as a multimer.\n",
      "(tensor([[[[     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          ...,\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf]],\n",
      "\n",
      "         [[  3.6154,  18.4525,  -6.7550],\n",
      "          [  4.9069,  18.2309,  -7.3973],\n",
      "          [  5.0126,  16.7958,  -7.9026],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[  5.1713,  15.8376,  -6.9893],\n",
      "          [  5.1827,  14.4347,  -7.3805],\n",
      "          [  3.7492,  14.0737,  -7.7474],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-14.4422,  10.9439,  18.5214],\n",
      "          [-15.6590,  11.2862,  19.2408],\n",
      "          [-15.9242,  12.7895,  19.1983],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [-14.9627,   7.0995,  23.9981],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[-17.1992,  13.1446,  19.3218],\n",
      "          [-17.6340,  14.5333,  19.3659],\n",
      "          [-18.8950,  14.6111,  20.2095],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          ...,\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf]]],\n",
      "\n",
      "\n",
      "        [[[     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          ...,\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf]],\n",
      "\n",
      "         [[  5.5952,   3.9914, -16.6107],\n",
      "          [  5.4519,   2.7667, -15.7643],\n",
      "          [  3.9747,   2.4462, -15.5106],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[  3.5657,   1.2340, -15.8865],\n",
      "          [  2.2174,   0.7319, -15.6074],\n",
      "          [  2.2307,  -0.7459, -15.2336],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-21.6609,  19.5785,   3.8419],\n",
      "          [-22.2091,  20.6122,   2.9605],\n",
      "          [-23.6840,  20.8817,   3.2722],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          ...,\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf],\n",
      "          [     inf,      inf,      inf]],\n",
      "\n",
      "         [[  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          ...,\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000]]]], device='cuda:0'), tensor([[[[125.9840,  -4.0120,  27.0100],\n",
      "          [127.0900,  -3.8040,  27.9390],\n",
      "          [128.1740,  -2.9460,  27.2950],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[128.9220,  -3.5160,  26.3500],\n",
      "          [129.9120,  -2.7380,  25.6180],\n",
      "          [129.1380,  -1.8200,  24.6810],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[129.4240,  -0.5160,  24.7480],\n",
      "          [128.7330,   0.4530,  23.9090],\n",
      "          [129.6860,   1.4840,  23.3250],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [123.0350,   2.1170,  25.2490],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[119.2390, -15.5050,   0.7320],\n",
      "          [118.6620, -16.7710,   1.1710],\n",
      "          [117.3940, -17.0050,   0.3600],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[117.3360, -18.1490,  -0.3160],\n",
      "          [116.1980, -18.4880,  -1.1560],\n",
      "          [114.9690, -18.8260,  -0.3150],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [119.4440, -21.6620,  -5.6320],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[113.7990, -18.6190,  -0.9110],\n",
      "          [112.5240, -18.9420,  -0.2870],\n",
      "          [111.5330, -19.2950,  -1.3830],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]]],\n",
      "\n",
      "\n",
      "        [[[ 27.9400,  27.5950,  22.1760],\n",
      "          [ 27.5830,  29.0060,  22.5200],\n",
      "          [ 26.5440,  29.0490,  23.6460],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[ 26.8880,  29.7390,  24.7340],\n",
      "          [ 25.9640,  29.9740,  25.8470],\n",
      "          [ 26.1160,  31.3780,  26.4210],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[ 24.9830,  32.0390,  26.6320],\n",
      "          [ 24.9560,  33.3710,  27.2230],\n",
      "          [ 24.4470,  33.2780,  28.6620],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -6.7590,  21.6670,  23.0640],\n",
      "          [ -8.0860,  21.2450,  23.4890],\n",
      "          [ -8.0630,  19.7290,  23.6450],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [-11.9990,  25.2040,  24.3750],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[ -8.4950,  19.2440,  24.8050],\n",
      "          [ -8.5030,  17.8050,  25.0790],\n",
      "          [ -9.7460,  17.3990,  25.8760],\n",
      "          ...,\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan],\n",
      "          [     nan,      nan,      nan]],\n",
      "\n",
      "         [[  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          ...,\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000]]]], dtype=torch.float64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "for item in train_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2f152-8acc-4e80-a6ae-5ad13ca4a251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
