{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5292db34-c268-45b2-a88c-9e5d8afd0455",
   "metadata": {},
   "source": [
    "# Testing out of box ESM sdk with antibodies using our antibody multimerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9433de10-bf77-4ed2-b421-2711adea3943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc30e2aa7a048d094333221249b0f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ESM3(\n",
       "  (encoder): EncodeInputs(\n",
       "    (sequence_embed): Embedding(64, 1536)\n",
       "    (plddt_projection): Linear(in_features=16, out_features=1536, bias=True)\n",
       "    (structure_per_res_plddt_projection): Linear(in_features=16, out_features=1536, bias=True)\n",
       "    (structure_tokens_embed): Embedding(4101, 1536)\n",
       "    (ss8_embed): Embedding(11, 1536)\n",
       "    (sasa_embed): Embedding(19, 1536)\n",
       "    (function_embed): ModuleList(\n",
       "      (0-7): 8 x Embedding(260, 192, padding_idx=0)\n",
       "    )\n",
       "    (residue_embed): EmbeddingBag(1478, 1536, mode='sum', padding_idx=0)\n",
       "  )\n",
       "  (transformer): TransformerStack(\n",
       "    (blocks): ModuleList(\n",
       "      (0): UnifiedTransformerBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (layernorm_qkv): Sequential(\n",
       "            (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "          )\n",
       "          (out_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (rotary): RotaryEmbedding()\n",
       "        )\n",
       "        (geom_attn): GeometricReasoningOriginalImpl(\n",
       "          (s_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (proj): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=1536, bias=False)\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1536, out_features=8192, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1-47): 47 x UnifiedTransformerBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (layernorm_qkv): Sequential(\n",
       "            (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "          )\n",
       "          (out_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (rotary): RotaryEmbedding()\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1536, out_features=8192, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_heads): OutputHeads(\n",
       "    (sequence_head): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=1536, out_features=64, bias=True)\n",
       "    )\n",
       "    (structure_head): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=1536, out_features=4096, bias=True)\n",
       "    )\n",
       "    (ss8_head): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=1536, out_features=11, bias=True)\n",
       "    )\n",
       "    (sasa_head): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=1536, out_features=19, bias=True)\n",
       "    )\n",
       "    (function_head): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=1536, out_features=2080, bias=True)\n",
       "    )\n",
       "    (residue_head): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=1536, out_features=1478, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from esm.pretrained import ESM3_sm_open_v0  # Loads ESM3 with appropriate parameters and weights\n",
    "from esm.tokenization.sequence_tokenizer import EsmSequenceTokenizer\n",
    "from esm.sdk.api import ESM3InferenceClient, GenerationConfig  # The SDK provides inference helpers\n",
    "\n",
    "# Setup device and load model from local weights.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Here we use the helper function to load the small open model (ESM3_sm_open_v1)\n",
    "model = ESM3_sm_open_v0(device)\n",
    "\n",
    "# Load the state dictionary from the file\n",
    "fpath = '/home/jupyter/DATA/model_weights/esm3_complete/esm3_sm_open_v1_state_dict.pt'\n",
    "state_dict = torch.load(fpath, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da5fa29-7ad4-465e-8423-1cc1dcbca3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ESM3InferenceClient() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Wrap the model in the SDK's inference client.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# The SDK (Software Development Kit) provides helper functions to run inference\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# (such as encoding sequences and generating predictions) without calling the model's\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# forward() method directly.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mESM3InferenceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ESM3InferenceClient() takes no arguments"
     ]
    }
   ],
   "source": [
    "# Wrap the model in the SDK's inference client.\n",
    "# The SDK (Software Development Kit) provides helper functions to run inference\n",
    "# (such as encoding sequences and generating predictions) without calling the model's\n",
    "# forward() method directly.\n",
    "client = ESM3InferenceClient(model=model, tokenizers=model.tokenizers, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db16b7-11d8-4468-b660-f6bf67d77531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Sequence to Structure\n",
    "# -------------------------------\n",
    "seq_tokenizer = EsmSequenceTokenizer()\n",
    "test_sequence = \"EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAISWNSGNTLYLQMNSLRAEDTAVYYCAR\"\n",
    "# Use the SDK's encode method, which wraps the tokenizer and prepares the input for the model.\n",
    "encoded_sequence = client.encode(test_sequence)\n",
    "print(\"Input sequence:\", test_sequence)\n",
    "print(\"Encoded sequence tensor shape:\", encoded_sequence.shape)\n",
    "\n",
    "# Generate structure tokens from the sequence.\n",
    "# Here we specify the generation configuration. Adjust num_steps and temperature as needed.\n",
    "gen_config = GenerationConfig(track=\"structure\", num_steps=10, temperature=0.1)\n",
    "with torch.no_grad():\n",
    "    output_seq2struct = client.generate(encoded_sequence, config=gen_config)\n",
    "\n",
    "print(\"\\n--- Sequence to Structure Output ---\")\n",
    "if hasattr(output_seq2struct, \"structure\") and output_seq2struct.structure is not None:\n",
    "    print(\"Structure tokens shape:\", output_seq2struct.structure.shape)\n",
    "else:\n",
    "    print(\"Full output from sequence-to-structure pass:\")\n",
    "    print(output_seq2struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fbfb7-47b6-4c78-9feb-9ce256e4af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bd884-87b3-4ea2-94b5-aba51d7bbf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685271f2-f7c4-4245-a33f-eb6d1f850b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6d57ad-81ed-43c3-ab9e-13d0136260f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAISWNSGNTLYLQMNSLRAEDTAVYYCAR\n",
      "Sequence tokens shape: torch.Size([1, 80])\n",
      "Sequence tokens are: [0, 9, 7, 16, 4, 7, 9, 8, 6, 6, 6, 4, 7, 16, 14, 6, 6, 8, 4, 10, 4, 8, 23, 5, 5, 8, 6, 18, 11, 18, 8, 8, 19, 5, 20, 8, 22, 7, 10, 16, 5, 14, 6, 15, 6, 4, 9, 22, 7, 8, 5, 12, 8, 22, 17, 8, 6, 17, 11, 4, 19, 4, 16, 20, 17, 8, 4, 10, 5, 9, 13, 11, 5, 7, 19, 19, 23, 5, 10, 2]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Sequence to Structure\n",
    "# -------------------------------\n",
    "seq_tokenizer = EsmSequenceTokenizer()\n",
    "test_sequence = \"EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAISWNSGNTLYLQMNSLRAEDTAVYYCAR\"\n",
    "seq_tokens = seq_tokenizer.encode(test_sequence)\n",
    "seq_tokens_tensor = torch.tensor(seq_tokens, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "print(\"Input sequence:\", test_sequence)\n",
    "print(\"Sequence tokens shape:\", seq_tokens_tensor.shape)\n",
    "print(\"Sequence tokens are:\", seq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acf3e83-daac-4fc4-9e7b-b4c72f6439f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESMOutput(sequence_logits=tensor([[[-19.6439, -19.6183, -19.5486,  ..., -19.6119, -19.6217, -19.5716],\n",
      "         [-18.8586, -18.7849, -18.7275,  ..., -18.7384, -18.8308, -18.8172],\n",
      "         [-18.8029, -18.8535, -18.7761,  ..., -18.8522, -18.8633, -18.9367],\n",
      "         ...,\n",
      "         [-23.5875, -23.5623, -23.5294,  ..., -23.6264, -23.2895, -23.5783],\n",
      "         [-21.1202, -21.2024, -21.2147,  ..., -21.2279, -21.1434, -21.3248],\n",
      "         [-20.3476, -20.3085, -20.2701,  ..., -20.3249, -20.2758, -20.3743]]],\n",
      "       device='cuda:0'), structure_logits=tensor([[[23.2422, 20.4796, 26.0145,  ..., 20.5472, 18.1796, 21.0636],\n",
      "         [19.5295, 22.4368, 20.5198,  ..., 21.4520, 13.8315, 15.8104],\n",
      "         [27.2014, 21.8847, 24.6682,  ..., 21.7292, 17.7618, 21.2891],\n",
      "         ...,\n",
      "         [25.4692, 13.9029, 28.3393,  ..., 13.9382, 13.2019, 18.0187],\n",
      "         [24.2239, 19.6468, 27.0249,  ..., 18.8914, 15.2234, 20.6710],\n",
      "         [23.8610, 22.1027, 24.8920,  ..., 21.5795, 17.7413, 19.7615]]],\n",
      "       device='cuda:0'), secondary_structure_logits=tensor([[[-1.8507e+01, -1.8606e+01, -1.8616e+01, -4.9297e+00, -4.0777e+00,\n",
      "          -7.1938e+00,  1.5310e+00, -3.2920e+00, -4.8814e+00,  1.3645e+00,\n",
      "           3.7123e+00],\n",
      "         [-1.8721e+01, -1.8790e+01, -1.8798e+01, -4.5424e+00, -7.6445e+00,\n",
      "          -1.0722e+01, -1.9148e+00, -5.4258e+00, -5.3692e+00,  9.2272e-01,\n",
      "           9.4125e+00],\n",
      "         [-1.8205e+01, -1.8237e+01, -1.8164e+01, -3.6274e+00, -4.2321e+00,\n",
      "          -8.7087e+00, -2.4752e+00, -1.1505e+00, -2.0699e+00,  2.0476e-01,\n",
      "           4.2820e+00],\n",
      "         [-1.7922e+01, -1.8024e+01, -1.7883e+01, -3.1040e+00, -2.7801e+00,\n",
      "          -9.4453e+00, -2.6458e+00,  3.4530e+00, -6.1200e-01, -7.1669e-01,\n",
      "           1.3900e+00],\n",
      "         [-1.9067e+01, -1.9081e+01, -1.9106e+01, -4.6304e+00, -5.0961e+00,\n",
      "          -1.4142e+01, -3.5048e+00,  4.8597e+00, -2.1190e-01, -2.1463e+00,\n",
      "           3.1133e+00],\n",
      "         [-1.9657e+01, -1.9652e+01, -1.9542e+01, -4.0404e+00, -4.1327e+00,\n",
      "          -1.1608e+01, -3.3045e+00,  6.1749e+00, -1.2030e+00, -4.7027e+00,\n",
      "           1.8898e+00],\n",
      "         [-1.7774e+01, -1.7848e+01, -1.7868e+01, -5.0448e+00, -2.6625e+00,\n",
      "          -1.1597e+01, -3.1075e+00,  5.5906e+00, -6.6538e-01, -2.2484e+00,\n",
      "           2.3636e+00],\n",
      "         [-1.5688e+01, -1.5801e+01, -1.5699e+01, -3.8507e+00, -5.3676e+00,\n",
      "          -1.1095e+01, -2.6772e+00,  5.9578e+00,  5.2102e-01, -2.5187e+00,\n",
      "           1.8244e+00],\n",
      "         [-1.7475e+01, -1.7417e+01, -1.7293e+01, -6.9883e+00, -8.2617e+00,\n",
      "          -1.2496e+01, -3.2299e+00,  1.9118e+00, -3.1524e+00,  2.2738e+00,\n",
      "           5.2297e+00],\n",
      "         [-1.7717e+01, -1.7758e+01, -1.7579e+01, -2.1822e+00, -5.2570e+00,\n",
      "          -1.0035e+01, -2.1016e+00, -2.5329e+00, -3.8341e+00, -2.1141e+00,\n",
      "           5.8448e+00],\n",
      "         [-1.7708e+01, -1.7741e+01, -1.7697e+01, -3.5392e+00, -4.6981e+00,\n",
      "          -1.0407e+01, -1.7452e+00,  3.4595e-01, -2.2657e+00,  2.0877e+00,\n",
      "           3.6246e+00],\n",
      "         [-1.6723e+01, -1.6808e+01, -1.6746e+01, -5.5087e+00, -4.8669e+00,\n",
      "          -9.1587e+00, -2.2303e+00, -3.0927e-01, -4.1036e+00,  1.2673e+00,\n",
      "           3.9494e+00],\n",
      "         [-1.8265e+01, -1.8266e+01, -1.8303e+01, -3.6178e+00, -4.4436e+00,\n",
      "          -1.2568e+01, -2.2095e+00,  1.2278e+00, -1.3293e+00, -1.1247e+00,\n",
      "           5.4908e+00],\n",
      "         [-2.0178e+01, -2.0231e+01, -2.0192e+01, -4.6097e+00, -5.2148e+00,\n",
      "          -1.0263e+01, -2.1134e+00, -1.8496e+00, -1.0321e+00, -1.8201e+00,\n",
      "           4.9562e+00],\n",
      "         [-1.9890e+01, -1.9876e+01, -1.9848e+01, -6.7895e-01, -3.8194e+00,\n",
      "          -1.0240e+01,  4.3304e+00, -3.6556e+00, -3.5219e+00, -4.5593e-01,\n",
      "          -1.5866e+00],\n",
      "         [-1.9046e+01, -1.8979e+01, -1.9005e+01, -3.7079e+00, -2.7592e+00,\n",
      "          -7.6480e+00,  5.3507e+00, -3.0895e+00, -3.6445e+00,  4.2818e-01,\n",
      "          -7.7412e-01],\n",
      "         [-1.6540e+01, -1.6344e+01, -1.6408e+01, -3.1903e+00, -5.0587e+00,\n",
      "          -9.6516e+00, -3.0881e+00, -6.5186e-01, -9.3197e-01,  4.9608e-01,\n",
      "           5.0285e+00],\n",
      "         [-1.7121e+01, -1.7150e+01, -1.7224e+01, -3.5161e+00, -5.3783e+00,\n",
      "          -1.0623e+01, -1.8995e+00,  5.3012e-01, -1.5442e+00, -2.7083e+00,\n",
      "           4.8561e+00],\n",
      "         [-2.0237e+01, -2.0266e+01, -2.0255e+01, -5.7010e+00, -5.1723e+00,\n",
      "          -1.4173e+01, -3.4464e+00,  3.7127e+00, -2.1427e+00, -2.0052e+00,\n",
      "           3.9119e+00],\n",
      "         [-2.0009e+01, -1.9984e+01, -1.9967e+01, -4.1702e+00, -7.1422e+00,\n",
      "          -1.2946e+01, -3.8349e+00,  5.5571e+00, -1.6103e+00, -4.8581e+00,\n",
      "           3.7763e+00],\n",
      "         [-1.9464e+01, -1.9467e+01, -1.9502e+01, -4.4691e+00, -4.7540e+00,\n",
      "          -1.1402e+01, -2.8075e+00,  4.7367e+00, -2.1746e+00, -3.3875e+00,\n",
      "           2.7667e+00],\n",
      "         [-1.7932e+01, -1.7951e+01, -1.7985e+01, -4.1839e+00, -4.4005e+00,\n",
      "          -1.0874e+01, -3.0145e+00,  5.9737e+00, -2.0355e-01, -2.8654e+00,\n",
      "           1.8780e+00],\n",
      "         [-1.9418e+01, -1.9417e+01, -1.9466e+01, -4.6112e+00, -4.1499e+00,\n",
      "          -1.1740e+01, -3.7468e+00,  6.0204e+00, -1.4556e+00, -4.0162e+00,\n",
      "           2.0948e+00],\n",
      "         [-1.9689e+01, -1.9689e+01, -1.9652e+01, -3.5457e+00, -4.4346e+00,\n",
      "          -1.2519e+01, -3.4161e+00,  4.6840e+00, -1.0988e+00, -2.9279e+00,\n",
      "           2.3615e+00],\n",
      "         [-1.7537e+01, -1.7565e+01, -1.7583e+01, -4.2026e+00, -3.6261e+00,\n",
      "          -1.0273e+01, -3.8771e+00,  6.1198e+00, -2.9229e+00, -2.5306e+00,\n",
      "           3.0688e+00],\n",
      "         [-1.5104e+01, -1.5234e+01, -1.5119e+01, -3.3390e+00, -5.3245e+00,\n",
      "          -1.0911e+01, -1.5303e+00,  4.2537e+00,  9.3386e-01, -3.3280e-01,\n",
      "           2.6052e+00],\n",
      "         [-1.7357e+01, -1.7393e+01, -1.7333e+01, -4.5940e+00, -6.5941e+00,\n",
      "          -1.4201e+01, -5.8436e-01,  5.3278e-01, -1.8328e+00,  7.6764e+00,\n",
      "          -1.6537e+00],\n",
      "         [-1.5124e+01, -1.5163e+01, -1.5167e+01, -3.2711e+00, -3.6291e+00,\n",
      "          -1.1239e+01, -9.4768e-01, -1.4756e+00, -1.1292e+00,  5.0358e+00,\n",
      "           4.6432e-01],\n",
      "         [-1.8445e+01, -1.8403e+01, -1.8409e+01, -2.8904e+00, -2.9331e+00,\n",
      "          -9.3935e+00, -1.0306e-01, -5.0470e+00, -4.5858e+00, -1.5621e+00,\n",
      "           4.6994e+00],\n",
      "         [-2.0767e+01, -2.0736e+01, -2.0739e+01,  2.5448e+00, -2.3161e+00,\n",
      "          -1.1695e+01,  3.3482e-01, -4.8743e+00, -4.2500e+00,  6.4899e-01,\n",
      "           5.7858e-01],\n",
      "         [-2.0055e+01, -2.0066e+01, -1.9964e+01,  3.5405e+00, -1.4553e+00,\n",
      "          -8.6941e+00,  1.8289e+00, -6.9242e+00, -6.0001e+00, -2.0442e-01,\n",
      "          -1.3828e+00],\n",
      "         [-1.6340e+01, -1.6342e+01, -1.6356e+01,  3.8979e+00, -1.1249e+00,\n",
      "          -7.9584e+00,  1.5862e+00, -4.4184e+00, -6.6713e+00,  7.4310e-01,\n",
      "          -1.6695e+00],\n",
      "         [-1.7145e+01, -1.7166e+01, -1.7214e+01, -2.3866e+00, -2.5422e+00,\n",
      "          -9.4022e+00, -2.4170e+00, -1.8124e+00, -2.2821e+00,  3.7630e+00,\n",
      "           7.2852e-01],\n",
      "         [-1.7841e+01, -1.7857e+01, -1.7872e+01, -3.8947e+00, -4.6621e+00,\n",
      "          -6.0749e+00, -2.1411e+00,  1.7193e+00, -3.5315e+00, -2.8810e+00,\n",
      "           3.9436e+00],\n",
      "         [-1.8497e+01, -1.8469e+01, -1.8448e+01, -4.2286e+00, -4.4040e+00,\n",
      "          -1.1402e+01, -3.3701e+00,  3.8783e+00,  1.5678e+00, -4.0632e+00,\n",
      "           2.1668e+00],\n",
      "         [-1.7933e+01, -1.7990e+01, -1.8007e+01, -2.7679e+00, -3.0408e+00,\n",
      "          -6.2550e+00, -2.4092e+00,  4.0384e+00, -1.4491e+00, -2.2054e+00,\n",
      "           2.0665e+00],\n",
      "         [-1.8335e+01, -1.8417e+01, -1.8454e+01, -2.6132e+00, -4.0126e+00,\n",
      "          -1.0127e+01, -2.3727e+00,  4.9223e+00, -1.7808e+00, -2.3517e+00,\n",
      "           8.4525e-01],\n",
      "         [-1.6737e+01, -1.6737e+01, -1.6806e+01, -3.1075e+00, -2.2052e+00,\n",
      "          -7.0942e+00, -2.3185e+00,  4.8660e+00, -2.8207e+00, -2.0462e+00,\n",
      "           1.4167e+00],\n",
      "         [-1.7905e+01, -1.7846e+01, -1.7986e+01, -4.2237e+00, -3.7859e+00,\n",
      "          -7.9711e+00, -3.2601e+00,  5.0568e+00, -2.0916e+00, -1.5491e+00,\n",
      "           1.2020e+00],\n",
      "         [-1.9537e+01, -1.9621e+01, -1.9557e+01, -3.0662e+00, -3.1533e+00,\n",
      "          -9.2306e+00, -2.1350e+00,  3.2663e+00, -8.1286e-01, -2.4547e+00,\n",
      "           8.0622e-01],\n",
      "         [-1.9578e+01, -1.9606e+01, -1.9652e+01, -4.9992e+00, -7.5473e+00,\n",
      "          -1.2498e+01, -2.8503e+00,  2.2524e+00, -6.8310e-01, -1.0089e+00,\n",
      "           4.1224e+00],\n",
      "         [-2.0708e+01, -2.0749e+01, -2.0652e+01, -5.1702e-01, -4.7702e+00,\n",
      "          -1.0776e+01,  4.2716e+00, -3.6657e+00, -4.0349e+00,  6.4829e-01,\n",
      "          -2.6508e+00],\n",
      "         [-1.8157e+01, -1.8200e+01, -1.8180e+01, -1.1359e+00, -4.7972e+00,\n",
      "          -1.2424e+01,  4.1973e+00, -3.2416e+00, -5.3045e+00,  5.0366e-01,\n",
      "          -2.1770e+00],\n",
      "         [-1.7195e+01, -1.7257e+01, -1.7234e+01, -3.3324e+00, -4.1116e+00,\n",
      "          -1.2181e+01, -5.8117e-01, -1.7568e+00, -2.3874e+00,  3.0586e+00,\n",
      "           2.3363e+00],\n",
      "         [-2.0151e+01, -2.0138e+01, -2.0229e+01, -4.7785e+00, -6.6709e+00,\n",
      "          -1.2619e+01, -2.2988e+00,  1.5338e+00, -3.3528e+00,  3.7638e-01,\n",
      "           4.1486e+00],\n",
      "         [-1.6780e+01, -1.6753e+01, -1.6777e+01, -4.0767e+00, -4.4284e+00,\n",
      "          -1.1744e+01, -2.4499e+00,  3.0026e+00, -1.0582e+00, -1.1752e+00,\n",
      "           3.1533e+00],\n",
      "         [-1.7329e+01, -1.7378e+01, -1.7299e+01, -3.5026e+00, -3.3858e+00,\n",
      "          -1.1547e+01, -3.3661e+00,  6.0122e+00, -9.0327e-01, -3.3160e+00,\n",
      "           1.1360e+00],\n",
      "         [-1.7628e+01, -1.7614e+01, -1.7610e+01, -3.4977e+00, -4.1666e+00,\n",
      "          -8.0992e+00, -3.6653e+00,  5.0812e+00, -1.1525e+00, -3.8182e+00,\n",
      "           2.3858e+00],\n",
      "         [-1.5457e+01, -1.5400e+01, -1.5388e+01, -2.5957e+00, -2.7100e+00,\n",
      "          -9.6015e+00, -8.9756e-01,  3.9210e+00, -1.9402e+00, -8.2414e-01,\n",
      "           2.4892e+00],\n",
      "         [-1.6609e+01, -1.6604e+01, -1.6659e+01, -2.6144e+00, -2.2252e+00,\n",
      "          -6.7907e+00,  8.6417e-02,  2.6803e+00, -3.3987e+00, -2.2039e-01,\n",
      "           1.5054e+00],\n",
      "         [-1.8833e+01, -1.8812e+01, -1.8809e+01, -2.5282e+00, -4.1505e+00,\n",
      "          -9.1283e+00, -1.5983e+00,  2.6610e+00, -2.0264e+00,  1.8498e-02,\n",
      "           1.7881e+00],\n",
      "         [-1.7422e+01, -1.7452e+01, -1.7382e+01, -3.3389e+00, -4.4382e+00,\n",
      "          -8.2084e+00, -2.3435e+00,  2.2386e+00, -4.2247e-01, -9.5700e-01,\n",
      "           2.0246e+00],\n",
      "         [-1.8489e+01, -1.8472e+01, -1.8424e+01, -3.6881e+00, -5.0880e+00,\n",
      "          -1.0055e+01, -1.6962e+00,  1.3352e+00, -2.4929e+00,  2.1566e-01,\n",
      "           2.2492e+00],\n",
      "         [-1.6639e+01, -1.6661e+01, -1.6615e+01, -2.6034e+00, -3.9307e+00,\n",
      "          -7.9746e+00, -5.2975e-01, -9.5764e-02, -1.7006e+00,  3.7956e-01,\n",
      "           1.8285e+00],\n",
      "         [-1.7461e+01, -1.7475e+01, -1.7425e+01, -1.6346e+00, -4.1522e+00,\n",
      "          -9.5511e+00, -3.6227e-02, -6.0348e-01, -2.5253e+00,  4.1739e-01,\n",
      "           1.4632e+00],\n",
      "         [-1.6060e+01, -1.6049e+01, -1.6014e+01, -1.4787e+00, -3.7025e+00,\n",
      "          -8.1140e+00,  8.3164e-01, -1.9390e+00, -2.4537e+00,  1.6028e+00,\n",
      "           3.9162e-01],\n",
      "         [-1.5824e+01, -1.5821e+01, -1.5801e+01, -9.5514e-01, -3.3331e+00,\n",
      "          -7.9925e+00,  1.7073e+00, -3.1054e+00, -3.8242e+00,  1.5951e+00,\n",
      "           6.8042e-01],\n",
      "         [-1.6491e+01, -1.6480e+01, -1.6504e+01, -1.0877e+00, -4.6352e+00,\n",
      "          -7.3878e+00,  1.9155e+00, -3.1083e+00, -4.4603e+00,  1.8304e+00,\n",
      "           7.5885e-01],\n",
      "         [-1.7314e+01, -1.7345e+01, -1.7328e+01, -4.1355e+00, -3.2964e+00,\n",
      "          -1.0188e+01, -3.0157e+00,  3.3570e+00,  5.4205e-02, -4.2465e-01,\n",
      "           1.1576e+00],\n",
      "         [-1.9741e+01, -1.9745e+01, -1.9702e+01, -4.2587e+00, -3.4365e+00,\n",
      "          -9.3169e+00, -2.7683e+00,  4.4062e+00, -7.2671e-01, -2.7230e+00,\n",
      "           1.1977e+00],\n",
      "         [-1.8790e+01, -1.8763e+01, -1.8775e+01, -5.0243e+00, -4.0557e+00,\n",
      "          -1.0074e+01, -3.8712e+00,  5.6606e+00, -3.6799e-01, -3.6202e+00,\n",
      "           3.2688e+00],\n",
      "         [-1.7836e+01, -1.7799e+01, -1.7778e+01, -2.5563e+00, -2.1986e+00,\n",
      "          -9.7921e+00, -2.3283e+00,  4.5208e+00, -2.0567e+00, -3.1979e+00,\n",
      "           9.7402e-01],\n",
      "         [-1.8087e+01, -1.8184e+01, -1.8037e+01, -4.0598e+00, -4.7033e+00,\n",
      "          -1.1584e+01, -3.9740e+00,  6.0844e+00, -5.7713e-01, -3.1546e+00,\n",
      "           2.4436e+00],\n",
      "         [-1.6819e+01, -1.6823e+01, -1.6858e+01, -3.2256e+00, -4.2123e+00,\n",
      "          -8.3149e+00, -2.8889e+00,  3.8369e+00, -3.6076e-01, -2.6733e+00,\n",
      "           2.2572e+00],\n",
      "         [-1.8565e+01, -1.8614e+01, -1.8550e+01, -4.8767e+00, -6.1023e+00,\n",
      "          -1.1443e+01, -1.2338e+00,  3.6223e+00, -3.0696e+00,  1.3851e+00,\n",
      "           3.7501e+00],\n",
      "         [-1.7022e+01, -1.7176e+01, -1.6952e+01, -6.1435e+00, -5.8901e+00,\n",
      "          -1.0227e+01, -1.3019e+00,  1.6927e+00, -4.0155e+00,  5.1761e+00,\n",
      "           1.3486e+00],\n",
      "         [-1.8080e+01, -1.8009e+01, -1.8070e+01, -2.2796e+00, -2.1749e+00,\n",
      "          -9.1839e+00, -1.7801e+00, -1.1681e+00, -1.3920e+00, -3.1689e+00,\n",
      "           4.1653e+00],\n",
      "         [-1.7246e+01, -1.7209e+01, -1.7302e+01, -3.0008e+00, -3.0905e+00,\n",
      "          -8.0343e+00, -4.3937e+00, -2.5313e+00, -1.1691e-02, -1.9196e+00,\n",
      "           5.2487e+00],\n",
      "         [-1.9613e+01, -1.9553e+01, -1.9571e+01,  4.2343e+00, -7.0242e-01,\n",
      "          -1.1897e+01,  2.0112e+00, -5.5964e+00, -6.4387e+00,  9.8112e-01,\n",
      "          -1.8393e+00],\n",
      "         [-1.8687e+01, -1.8640e+01, -1.8637e+01,  3.1026e+00, -3.3092e+00,\n",
      "          -1.2175e+01,  1.3536e+00, -5.4632e+00, -6.2658e+00, -6.4025e-01,\n",
      "          -1.0783e+00],\n",
      "         [-1.8079e+01, -1.7939e+01, -1.7970e+01,  2.8464e+00, -1.9196e+00,\n",
      "          -1.2275e+01,  1.0644e+00, -6.1107e+00, -4.7188e+00, -6.5437e-01,\n",
      "           5.8353e-01],\n",
      "         [-1.5695e+01, -1.5648e+01, -1.5687e+01, -5.9995e-01, -5.7830e+00,\n",
      "          -7.4535e+00, -2.4649e+00, -3.4779e+00, -4.2350e+00,  8.7181e-01,\n",
      "           4.9275e+00],\n",
      "         [-1.5636e+01, -1.5671e+01, -1.5788e+01, -3.7784e+00, -5.0403e+00,\n",
      "          -9.7468e+00, -2.9684e+00,  1.6898e+00, -2.0093e+00,  3.4885e+00,\n",
      "           2.7427e+00],\n",
      "         [-1.6406e+01, -1.6432e+01, -1.6400e+01, -2.9408e+00, -2.4317e+00,\n",
      "          -7.2434e+00, -1.8454e+00,  3.8338e+00, -1.2400e+00, -1.1409e+00,\n",
      "           1.3264e+00],\n",
      "         [-1.5880e+01, -1.5932e+01, -1.5841e+01, -4.3361e+00, -2.9473e+00,\n",
      "          -9.2074e+00, -3.2384e+00,  4.3952e+00, -4.9784e-01, -2.9741e+00,\n",
      "           3.3558e+00],\n",
      "         [-1.7787e+01, -1.7877e+01, -1.7825e+01, -3.0205e+00, -4.3949e+00,\n",
      "          -8.9722e+00, -3.3060e+00,  5.5186e+00, -1.4613e+00, -3.2553e+00,\n",
      "           1.8056e+00],\n",
      "         [-1.7329e+01, -1.7397e+01, -1.7377e+01, -3.2129e+00, -2.4183e+00,\n",
      "          -8.9534e+00, -2.2382e+00,  5.1266e+00, -2.1186e+00, -2.3225e+00,\n",
      "           1.8830e+00],\n",
      "         [-2.0257e+01, -2.0327e+01, -2.0289e+01, -3.3729e+00, -4.0981e+00,\n",
      "          -1.0864e+01, -2.0641e+00,  4.6452e+00,  1.5102e+00, -6.4186e+00,\n",
      "           2.4227e+00],\n",
      "         [-1.8783e+01, -1.8838e+01, -1.8836e+01, -4.1615e+00, -6.0901e+00,\n",
      "          -1.0700e+01, -1.8927e+00,  8.5227e-01, -2.1814e+00, -3.6663e+00,\n",
      "           8.0966e+00],\n",
      "         [-1.8090e+01, -1.8106e+01, -1.8026e+01, -5.1275e+00, -3.5661e+00,\n",
      "          -7.8591e+00,  4.6517e-01, -1.4157e+00, -1.8476e+00,  1.3434e+00,\n",
      "           3.0193e+00]]], device='cuda:0'), sasa_logits=tensor([[[-19.1724, -19.2187, -19.1880,  ...,  -1.4249,  -1.7230,  -2.1828],\n",
      "         [-22.0195, -22.0318, -21.9360,  ...,   0.5302,   1.8179,   3.2163],\n",
      "         [-16.8851, -16.8855, -16.8632,  ...,  -2.9794,  -4.1209,  -5.2753],\n",
      "         ...,\n",
      "         [-18.4832, -18.4639, -18.5726,  ...,  -5.3647,  -6.6697,  -8.2739],\n",
      "         [-16.3726, -16.4116, -16.3961,  ...,   0.9980,   1.5921,   1.5239],\n",
      "         [-18.0612, -18.0960, -18.1174,  ...,  -1.8812,  -2.2382,  -2.9281]]],\n",
      "       device='cuda:0'), function_logits=tensor([[[[ -4.3449,  -4.4276,  -4.4760,  ...,  44.0031,  45.1406,  45.0893],\n",
      "          [ -4.5465,  -4.2674,  -4.4070,  ...,  42.6787,  44.2884,  44.3974],\n",
      "          [ -4.6856,  -4.7575,  -4.8152,  ...,  47.8210,  43.6340,  45.8767],\n",
      "          ...,\n",
      "          [ -4.4456,  -4.3037,  -4.3577,  ...,  44.3778,  44.0761,  42.1391],\n",
      "          [ -4.5579,  -4.7079,  -4.7782,  ...,  51.1595,  49.2216,  44.5570],\n",
      "          [ -5.0390,  -4.8474,  -4.9195,  ...,  43.2237,  47.1386,  41.2683]],\n",
      "\n",
      "         [[ -5.3729,  -5.5814,  -5.5553,  ...,  45.2676,  49.2305,  47.3978],\n",
      "          [ -5.6109,  -5.4472,  -5.4734,  ...,  44.9628,  47.5080,  47.7815],\n",
      "          [ -5.5878,  -5.6123,  -5.6505,  ...,  52.0783,  49.5651,  50.4434],\n",
      "          ...,\n",
      "          [ -5.4131,  -5.5582,  -5.3962,  ...,  48.9754,  47.4424,  47.5803],\n",
      "          [ -5.8030,  -5.7890,  -5.8163,  ...,  50.9929,  50.3001,  45.8223],\n",
      "          [ -5.9226,  -5.7256,  -5.7864,  ...,  47.1187,  49.9255,  45.4276]],\n",
      "\n",
      "         [[ -9.7528,  -9.8856,  -9.9411,  ...,  41.0593,  45.4265,  44.9203],\n",
      "          [ -9.9139,  -9.8258,  -9.7989,  ...,  42.2655,  43.3646,  42.3316],\n",
      "          [ -9.7683,  -9.8424,  -9.8125,  ...,  48.9387,  43.6937,  46.0140],\n",
      "          ...,\n",
      "          [ -9.7224,  -9.7378,  -9.5425,  ...,  45.3619,  46.1779,  44.2471],\n",
      "          [-10.1327, -10.0897, -10.0888,  ...,  46.5701,  46.5379,  42.9481],\n",
      "          [-10.1798, -10.0957, -10.0215,  ...,  42.8968,  47.4354,  39.3864]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-10.0351, -10.2194, -10.3337,  ...,  30.9988,  35.8650,  32.0499],\n",
      "          [-10.5272, -10.4452, -10.4604,  ...,  31.4746,  33.3210,  31.9083],\n",
      "          [ -9.9931, -10.0233, -10.1735,  ...,  36.8476,  33.0504,  34.5538],\n",
      "          ...,\n",
      "          [-10.0851, -10.2088,  -9.9771,  ...,  33.8582,  30.6952,  33.1399],\n",
      "          [-10.4546, -10.4033, -10.4678,  ...,  34.3102,  34.7484,  28.9107],\n",
      "          [-10.4558, -10.2949, -10.3308,  ...,  31.6688,  35.5514,  32.7160]],\n",
      "\n",
      "         [[ -9.7686, -10.0087, -10.0798,  ...,  34.5102,  40.0961,  36.7574],\n",
      "          [-10.2316, -10.1726, -10.2138,  ...,  35.0927,  36.8101,  35.3622],\n",
      "          [ -9.9790,  -9.9754, -10.0828,  ...,  41.0274,  35.7243,  37.6340],\n",
      "          ...,\n",
      "          [ -9.8775, -10.0749,  -9.8129,  ...,  37.3272,  34.8391,  35.3369],\n",
      "          [-10.3152, -10.2333, -10.2937,  ...,  38.3612,  39.5926,  32.8016],\n",
      "          [-10.3976, -10.1627, -10.2022,  ...,  34.7393,  39.0193,  35.2973]],\n",
      "\n",
      "         [[-10.3925, -10.5891, -10.5389,  ...,  34.4154,  37.9065,  35.1763],\n",
      "          [-10.6676, -10.5399, -10.4955,  ...,  33.4382,  35.1444,  35.4403],\n",
      "          [-10.4584, -10.4031, -10.5730,  ...,  38.8336,  35.2985,  36.4350],\n",
      "          ...,\n",
      "          [-10.2670, -10.3369, -10.2219,  ...,  35.2768,  33.2270,  33.4065],\n",
      "          [-10.6421, -10.5622, -10.6745,  ...,  37.3320,  38.0521,  33.8609],\n",
      "          [-10.5885, -10.4386, -10.4558,  ...,  35.2199,  36.3875,  34.5181]]]],\n",
      "       device='cuda:0'), residue_logits=tensor([[[ 1.4365e-01, -3.7749e-01, -2.5933e-01,  ..., -1.5507e+01,\n",
      "          -1.5460e+01, -1.2297e+01],\n",
      "         [-2.0260e-01, -1.0625e+00, -1.7201e-01,  ..., -1.4663e+01,\n",
      "          -1.5088e+01, -1.3253e+01],\n",
      "         [-3.3336e-01, -1.3567e+00, -4.3918e-01,  ..., -1.4862e+01,\n",
      "          -1.5044e+01, -1.2133e+01],\n",
      "         ...,\n",
      "         [-3.6388e-01, -3.3161e-01,  2.6513e-03,  ..., -1.4818e+01,\n",
      "          -1.4967e+01, -1.2051e+01],\n",
      "         [-1.6779e-01, -3.4648e-01,  1.9169e-02,  ..., -1.4407e+01,\n",
      "          -1.3431e+01, -1.1213e+01],\n",
      "         [-4.6891e-02, -2.0593e-01,  2.0656e-01,  ..., -1.3893e+01,\n",
      "          -1.4372e+01, -1.1750e+01]]], device='cuda:0'), embeddings=tensor([[[ -10.5759,   69.6637,  -95.5638,  ...,  -39.8310,  -39.6379,\n",
      "             5.3294],\n",
      "         [  56.1839,   18.7739,   17.9884,  ...,  -11.7651, -226.6192,\n",
      "          -137.0656],\n",
      "         [-104.6563,   58.5026,  150.9370,  ...,   10.5585, -339.7291,\n",
      "          -111.5872],\n",
      "         ...,\n",
      "         [-167.7341,  -57.9890,  -40.7361,  ..., -257.9982,  131.0216,\n",
      "             0.5724],\n",
      "         [  74.8578,  -90.6054,  182.4805,  ...,  -54.2046,   23.8606,\n",
      "            22.7971],\n",
      "         [-116.5537,   47.2033,  138.1271,  ...,   32.2213, -117.9444,\n",
      "            25.3602]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    # Pass the dictionary to the model\n",
    "    results = model.forward(sequence_tokens=seq_tokens_tensor)\n",
    "\n",
    "\n",
    "# print(\"\\n--- Sequence to Structure Output ---\")\n",
    "# if \"structure_tokens\" in result:\n",
    "#     structure_tokens = result[\"structure_tokens\"]\n",
    "#     print(\"Structure tokens shape:\", structure_tokens.shape)\n",
    "# else:\n",
    "#     print(\"Full output from sequence-to-structure pass:\")\n",
    "#     print(result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687a1b2-3522-4aab-9fd1-6114ae3db69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Partially Masked Sequence to Infilled Sequence\n",
    "# -------------------------------\n",
    "# Test: mask a segment of the input sequence and let the model fill it in.\n",
    "mask_token_id = seq_tokenizer.mask_token_id  # Mask token as defined by the tokenizer\n",
    "masked_seq_tokens = seq_tokens.copy()\n",
    "# For demonstration, mask tokens at positions 10 through 15.\n",
    "for i in range(10, 16):\n",
    "    masked_seq_tokens[i] = mask_token_id\n",
    "masked_seq_tokens_tensor = torch.tensor(masked_seq_tokens, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "print(\"\\n--- Partially Masked Sequence ---\")\n",
    "print(\"Masked sequence tokens:\", masked_seq_tokens_tensor)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # We assume the model can perform masked token prediction; this may be part of the forward pass\n",
    "    # or a separate generation/inpainting routine.\n",
    "    output_mask = model(masked_seq_tokens_tensor)\n",
    "    # We assume that the output contains a key \"sequence\" with the predicted full sequence tokens.\n",
    "    if \"sequence\" in output_mask:\n",
    "        predicted_seq_tokens = output_mask[\"sequence\"]\n",
    "        infilled_sequence = seq_tokenizer.decode(predicted_seq_tokens.squeeze(0).tolist())\n",
    "        print(\"Infilled sequence:\")\n",
    "        print(infilled_sequence)\n",
    "    else:\n",
    "        print(\"Masked sequence infilling output:\")\n",
    "        print(output_mask)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Inverse – Structure to Sequence\n",
    "# -------------------------------\n",
    "# Test: Given structure output, attempt to recover a sequence.\n",
    "# This inverse operation is not standard in every model.\n",
    "# Here we assume that our model has a method called invert_structure().\n",
    "print(\"\\n--- Inverse: Structure to Sequence ---\")\n",
    "if \"structure_tokens\" in output_seq2struct:\n",
    "    with torch.no_grad():\n",
    "        # Check if the model has an 'invert_structure' method.\n",
    "        if hasattr(model, \"invert_structure\"):\n",
    "            # Pass the structure tokens to the inverse method.\n",
    "            output_struct2seq = model.invert_structure(structure_tokens)\n",
    "            if \"sequence\" in output_struct2seq:\n",
    "                recovered_seq_tokens = output_struct2seq[\"sequence\"]\n",
    "                recovered_sequence = seq_tokenizer.decode(recovered_seq_tokens.squeeze(0).tolist())\n",
    "                print(\"Recovered sequence from structure:\")\n",
    "                print(recovered_sequence)\n",
    "            else:\n",
    "                print(\"Inverse structure-to-sequence output:\")\n",
    "                print(output_struct2seq)\n",
    "        else:\n",
    "            print(\"Model does not implement an invert_structure method. Inverse operation not supported.\")\n",
    "else:\n",
    "    print(\"No structure tokens available from sequence-to-structure pass; cannot run inverse operation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2453503-2177-4a8f-a87c-084bcea668eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ESM3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup device and load the model with local weights.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mESM3\u001b[49m() \n\u001b[1;32m      4\u001b[0m local_weights_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jupyter/DATA/model_weights/esm3_complete/esm3_sm_open_v1_state_dict.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(local_weights_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ESM3' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup device and load the model with local weights.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "local_weights_path = \"/home/jupyter/DATA/model_weights/esm3_complete/esm3_sm_open_v1_state_dict.pt\"\n",
    "state_dict = torch.load(local_weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f3562-e069-46f6-a5e1-95b97ced0dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.sequence_embed.weight: torch.Size([64, 1536])\n",
      "encoder.plddt_projection.weight: torch.Size([1536, 16])\n",
      "encoder.plddt_projection.bias: torch.Size([1536])\n",
      "encoder.structure_per_res_plddt_projection.weight: torch.Size([1536, 16])\n",
      "encoder.structure_per_res_plddt_projection.bias: torch.Size([1536])\n",
      "encoder.structure_tokens_embed.weight: torch.Size([4101, 1536])\n",
      "encoder.ss8_embed.weight: torch.Size([11, 1536])\n",
      "encoder.sasa_embed.weight: torch.Size([19, 1536])\n",
      "encoder.function_embed.0.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.1.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.2.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.3.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.4.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.5.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.6.weight: torch.Size([260, 192])\n",
      "encoder.function_embed.7.weight: torch.Size([260, 192])\n",
      "encoder.residue_embed.weight: torch.Size([1478, 1536])\n",
      "transformer.blocks.0.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.0.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.0.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.0.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.0.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.0.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.0.geom_attn.distance_scale_per_head: torch.Size([256])\n",
      "transformer.blocks.0.geom_attn.rotation_scale_per_head: torch.Size([256])\n",
      "transformer.blocks.0.geom_attn.s_norm.weight: torch.Size([1536])\n",
      "transformer.blocks.0.geom_attn.proj.weight: torch.Size([3840, 1536])\n",
      "transformer.blocks.0.geom_attn.out_proj.weight: torch.Size([1536, 768])\n",
      "transformer.blocks.0.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.0.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.0.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.0.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.1.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.1.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.1.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.1.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.1.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.1.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.1.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.1.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.1.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.1.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.2.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.2.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.2.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.2.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.2.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.2.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.2.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.2.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.2.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.2.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.3.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.3.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.3.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.3.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.3.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.3.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.3.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.3.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.3.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.3.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.4.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.4.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.4.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.4.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.4.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.4.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.4.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.4.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.4.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.4.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.5.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.5.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.5.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.5.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.5.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.5.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.5.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.5.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.5.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.5.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.6.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.6.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.6.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.6.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.6.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.6.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.6.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.6.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.6.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.6.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.7.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.7.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.7.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.7.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.7.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.7.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.7.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.7.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.7.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.7.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.8.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.8.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.8.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.8.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.8.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.8.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.8.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.8.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.8.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.8.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.9.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.9.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.9.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.9.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.9.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.9.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.9.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.9.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.9.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.9.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.10.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.10.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.10.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.10.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.10.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.10.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.10.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.10.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.10.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.10.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.11.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.11.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.11.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.11.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.11.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.11.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.11.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.11.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.11.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.11.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.12.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.12.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.12.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.12.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.12.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.12.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.12.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.12.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.12.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.12.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.13.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.13.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.13.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.13.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.13.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.13.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.13.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.13.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.13.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.13.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.14.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.14.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.14.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.14.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.14.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.14.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.14.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.14.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.14.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.14.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.15.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.15.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.15.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.15.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.15.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.15.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.15.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.15.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.15.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.15.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.16.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.16.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.16.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.16.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.16.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.16.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.16.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.16.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.16.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.16.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.17.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.17.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.17.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.17.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.17.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.17.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.17.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.17.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.17.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.17.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.18.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.18.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.18.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.18.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.18.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.18.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.18.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.18.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.18.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.18.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.19.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.19.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.19.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.19.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.19.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.19.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.19.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.19.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.19.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.19.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.20.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.20.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.20.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.20.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.20.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.20.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.20.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.20.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.20.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.20.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.21.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.21.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.21.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.21.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.21.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.21.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.21.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.21.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.21.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.21.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.22.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.22.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.22.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.22.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.22.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.22.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.22.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.22.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.22.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.22.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.23.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.23.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.23.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.23.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.23.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.23.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.23.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.23.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.23.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.23.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.24.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.24.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.24.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.24.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.24.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.24.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.24.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.24.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.24.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.24.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.25.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.25.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.25.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.25.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.25.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.25.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.25.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.25.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.25.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.25.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.26.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.26.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.26.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.26.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.26.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.26.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.26.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.26.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.26.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.26.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.27.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.27.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.27.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.27.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.27.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.27.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.27.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.27.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.27.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.27.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.28.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.28.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.28.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.28.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.28.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.28.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.28.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.28.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.28.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.28.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.29.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.29.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.29.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.29.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.29.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.29.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.29.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.29.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.29.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.29.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.30.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.30.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.30.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.30.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.30.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.30.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.30.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.30.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.30.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.30.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.31.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.31.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.31.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.31.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.31.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.31.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.31.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.31.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.31.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.31.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.32.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.32.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.32.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.32.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.32.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.32.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.32.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.32.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.32.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.32.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.33.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.33.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.33.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.33.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.33.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.33.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.33.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.33.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.33.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.33.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.34.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.34.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.34.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.34.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.34.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.34.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.34.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.34.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.34.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.34.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.35.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.35.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.35.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.35.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.35.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.35.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.35.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.35.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.35.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.35.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.36.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.36.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.36.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.36.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.36.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.36.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.36.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.36.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.36.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.36.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.37.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.37.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.37.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.37.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.37.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.37.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.37.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.37.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.37.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.37.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.38.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.38.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.38.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.38.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.38.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.38.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.38.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.38.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.38.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.38.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.39.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.39.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.39.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.39.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.39.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.39.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.39.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.39.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.39.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.39.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.40.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.40.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.40.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.40.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.40.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.40.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.40.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.40.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.40.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.40.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.41.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.41.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.41.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.41.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.41.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.41.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.41.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.41.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.41.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.41.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.42.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.42.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.42.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.42.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.42.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.42.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.42.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.42.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.42.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.42.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.43.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.43.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.43.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.43.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.43.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.43.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.43.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.43.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.43.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.43.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.44.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.44.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.44.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.44.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.44.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.44.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.44.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.44.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.44.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.44.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.45.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.45.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.45.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.45.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.45.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.45.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.45.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.45.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.45.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.45.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.46.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.46.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.46.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.46.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.46.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.46.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.46.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.46.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.46.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.46.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.blocks.47.attn.layernorm_qkv.0.weight: torch.Size([1536])\n",
      "transformer.blocks.47.attn.layernorm_qkv.0.bias: torch.Size([1536])\n",
      "transformer.blocks.47.attn.layernorm_qkv.1.weight: torch.Size([4608, 1536])\n",
      "transformer.blocks.47.attn.out_proj.weight: torch.Size([1536, 1536])\n",
      "transformer.blocks.47.attn.q_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.47.attn.k_ln.weight: torch.Size([1536])\n",
      "transformer.blocks.47.ffn.0.weight: torch.Size([1536])\n",
      "transformer.blocks.47.ffn.0.bias: torch.Size([1536])\n",
      "transformer.blocks.47.ffn.1.weight: torch.Size([8192, 1536])\n",
      "transformer.blocks.47.ffn.3.weight: torch.Size([1536, 4096])\n",
      "transformer.norm.weight: torch.Size([1536])\n",
      "Total number of parameters: 1375643648\n"
     ]
    }
   ],
   "source": [
    "state_dict = loaded_backbone_model.state_dict()\n",
    "for key, tensor in state_dict.items():\n",
    "    print(f\"{key}: {tensor.shape}\")\n",
    "    \n",
    "total_params = sum(p.numel() for p in loaded_backbone_model.parameters())\n",
    "print(\"Total number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7d61c-5797-4369-ba1d-d0d6a12d8f04",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explainer: Transformer Block with Geometric Attention in ESM3\n",
    "\n",
    "In the ESM3 architecture, the **first transformer block** is unique because it integrates a specialized module for geometric reasoning, which is crucial for capturing structural relationships (e.g., in protein data).\n",
    "```\n",
    "TransformerStack(\n",
    "  (blocks): ModuleList(\n",
    "    (0): UnifiedTransformerBlock(\n",
    "      (attn): MultiHeadAttention(\n",
    "        (layernorm_qkv): Sequential(\n",
    "          (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "          (1): Linear(in_features=1536, out_features=4608, bias=False)\n",
    "        )\n",
    "        (out_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
    "        (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (rotary): RotaryEmbedding()\n",
    "      )\n",
    "      (geom_attn): GeometricReasoningOriginalImpl(\n",
    "        (s_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (proj): Linear(in_features=1536, out_features=3840, bias=False)\n",
    "        (out_proj): Linear(in_features=768, out_features=1536, bias=False)\n",
    "      )\n",
    "      (ffn): Sequential(\n",
    "        (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (1): Linear(in_features=1536, out_features=8192, bias=False)\n",
    "        (2): SwiGLU()\n",
    "        (3): Linear(in_features=4096, out_features=1536, bias=False)\n",
    "      )\n",
    "    )\n",
    "    (1-47): 47 x UnifiedTransformerBlock(\n",
    "      (attn): MultiHeadAttention(\n",
    "        (layernorm_qkv): Sequential(\n",
    "          (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "          (1): Linear(in_features=1536, out_features=4608, bias=False)\n",
    "        )\n",
    "        (out_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
    "        (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (rotary): RotaryEmbedding()\n",
    "      )\n",
    "      (ffn): Sequential(\n",
    "        (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "        (1): Linear(in_features=1536, out_features=8192, bias=False)\n",
    "        (2): SwiGLU()\n",
    "        (3): Linear(in_features=4096, out_features=1536, bias=False)\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
    "```\n",
    "\n",
    "Below is a breakdown of its components:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Multi-Head Self-Attention (`attn`)\n",
    "\n",
    "- **Purpose:**  \n",
    "  Processes the input sequence by allowing each token to attend to every other token.\n",
    "\n",
    "- **Key Components:**  \n",
    "  - **Layer Normalization & Linear Projections:**  \n",
    "    Prepares the queries, keys, and values for attention computation.\n",
    "  - **Rotary Embeddings:**  \n",
    "    Enhances the attention mechanism by incorporating relative positional information.\n",
    "  - **Output Projection:**  \n",
    "    Consolidates the attention outputs back into the original embedding space.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Geometric Attention (`geom_attn`)\n",
    "\n",
    "- **Purpose:**  \n",
    "  Enhances the transformer block by integrating geometric or structural information. This is particularly important for applications like protein structure prediction where spatial relationships are key.\n",
    "\n",
    "- **Key Components:**\n",
    "  - **Layer Normalization (`s_norm`):**  \n",
    "    Normalizes the input prior to geometric processing.\n",
    "  - **Projection (`proj`):**  \n",
    "    Maps the 1536-dimensional input into a higher-dimensional space (3840 dimensions) to capture more complex geometric features.\n",
    "  - **Output Projection (`out_proj`):**  \n",
    "    Reduces the dimensionality from 768 (after geometric processing) back to 1536, ensuring compatibility with the rest of the network.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Feed-Forward Network (`ffn`)\n",
    "\n",
    "- **Purpose:**  \n",
    "  Applies further non-linear transformations to the output from the attention mechanisms.\n",
    "\n",
    "- **Key Components:**\n",
    "  - **Layer Normalization:**  \n",
    "    Prepares the data for the feed-forward operations.\n",
    "  - **Intermediate Linear Layer (Expansion to 8192 dimensions):**  \n",
    "    Expands the feature space to allow for complex representations.\n",
    "  - **SwiGLU Activation:**  \n",
    "    A non-linear activation that enhances the model’s expressivity.\n",
    "  - **Final Linear Projection:**  \n",
    "    Compresses the expanded representation back to the original 1536 dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The **first transformer block** in ESM3 is a **UnifiedTransformerBlock** that stands out due to the integration of **geometric attention**. This extra module (`geom_attn`) augments the standard self-attention mechanism by incorporating geometric reasoning, making the block adept at handling structural data alongside sequence information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ab006-ede5-4890-ae35-a52a2bca6f60",
   "metadata": {},
   "source": [
    "# esm encoder+transformer block unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21256c93-060e-4f20-a7dc-c73cbd0d4709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from esm.tokenization.sequence_tokenizer import EsmSequenceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69a8873e-8091-401d-8c52-ba603f22dc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence tokens shape: torch.Size([1, 17])\n"
     ]
    }
   ],
   "source": [
    "# for ESM3\n",
    "# Initialize sequence \n",
    "seq_tokenizer = EsmSequenceTokenizer()\n",
    "test_sequence = \"CSSDGSYGFGAMDYW\"\n",
    "seq_tokens = seq_tokenizer.encode(test_sequence)\n",
    "seq_tokens_tensor = torch.tensor(seq_tokens, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "print(\"Sequence tokens shape:\", seq_tokens_tensor.shape)\n",
    "\n",
    "# Create required tensors\n",
    "# dummy_average_plddt = torch.ones(seq_tokens_tensor.shape, dtype=torch.float32, device=device)\n",
    "# dummy_per_res_plddt = torch.ones(seq_tokens_tensor.shape, dtype=torch.float32, device=device)\n",
    "# dummy_structure_tokens = torch.zeros(seq_tokens_tensor.shape, dtype=torch.int64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd8ace0c-6456-4df7-9cbf-b2cdf4442d93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([1, 17, 1536])\n",
      "tensor([[[ 7.7637e-02, -1.7578e-02,  4.1016e-02,  ..., -2.9541e-02,\n",
      "          -1.9653e-02, -6.3324e-04],\n",
      "         [ 6.5308e-03,  2.5879e-02, -8.4473e-02,  ..., -3.1250e-02,\n",
      "          -8.1543e-02,  1.2500e-01],\n",
      "         [ 1.1035e-01, -8.0566e-02, -1.2061e-01,  ...,  6.2256e-02,\n",
      "          -2.2339e-02, -5.4688e-02],\n",
      "         ...,\n",
      "         [ 2.0599e-04,  1.5625e-01,  9.5703e-02,  ...,  1.1914e-01,\n",
      "          -4.3701e-02,  5.5664e-02],\n",
      "         [-3.1006e-02, -1.2451e-02,  2.6367e-01,  ..., -1.8164e-01,\n",
      "          -7.3242e-02,  2.2168e-01],\n",
      "         [ 5.9814e-02,  2.9907e-02,  1.7334e-02,  ..., -3.1250e-02,\n",
      "          -2.1729e-02, -1.6235e-02]]], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# TEST SEQUENCE EMBEDDINGS\n",
    "with torch.no_grad():\n",
    "    embeddings = loaded_backbone_model.encoder.sequence_embed(seq_tokens_tensor)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1478ac3-9858-46f0-8988-061f1bbafc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64add07c-498a-4ada-86f6-093e941c830c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951ba48-d078-4a47-871a-7b435469bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac6a4c-9319-41b8-b9d1-b897584e00fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e16546-955b-444f-96cf-ab94e91925fc",
   "metadata": {},
   "source": [
    "## load inputs (sequence or pdb structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a09dbaf-035c-44a0-b5c3-f14b93bf75e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load amino acid sequence string input\n",
    "seq_tokenizer = EsmSequenceTokenizer()\n",
    "test_sequence = \"CSSDGSYGFGAMDYW\"\n",
    "seq_tokens = seq_tokenizer.encode(test_sequence)\n",
    "seq_tokens_tensor = torch.tensor(seq_tokens, dtype=torch.int64).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d297937-5e1c-4db3-9588-615d12c061f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from esm.utils.structure.protein_chain import ProteinChain\n",
    "fpath = '/home/jupyter/1BEY.pdb'\n",
    "protein_chain = ProteinChain.from_pdb(path=fpath, chain_id='H')\n",
    "atom37 = protein_chain.atom37_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08df26-902e-4fb0-aea4-83ce0108b1e3",
   "metadata": {},
   "source": [
    "## ** TODO: how do we pass a multimer structure into ESM3?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84590bdb-4716-4f4b-95cd-023464f9ef24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinChain(id='1BEY', sequence='QVQLQESGPGLVRPSQTLSLTCTVSGFTFTDFYMNWVRQPPGRGLEWIGFIRDKAKGYTTEYNPSVKGRVTMLVDTSKNQFSLRLSSVTAADTAVYYCAREGHTAAPFDYWGQGSLVTVSSASTKGPSVFPLAPAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKV', chain_id='H', entity_id=1, residue_index=array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "       166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "       179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "       192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "       205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "       218, 219]), insertion_code=array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', ''], dtype='<U4'), atom37_positions=array([[[ 7.929, 79.104, 42.518],\n",
       "        [ 6.897, 79.705, 43.426],\n",
       "        [ 7.205, 79.372, 44.891],\n",
       "        ...,\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan]],\n",
       "\n",
       "       [[ 6.715, 78.186, 45.269],\n",
       "        [ 6.801, 77.592, 46.599],\n",
       "        [ 7.716, 76.363, 46.672],\n",
       "        ...,\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan]],\n",
       "\n",
       "       [[ 8.269, 76.103, 47.849],\n",
       "        [ 9.18 , 74.978, 48.013],\n",
       "        [ 8.849, 74.05 , 49.195],\n",
       "        ...,\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[33.28 , 63.064, 39.117],\n",
       "        [34.236, 62.546, 38.163],\n",
       "        [34.165, 63.25 , 36.793],\n",
       "        ...,\n",
       "        [   nan,    nan,    nan],\n",
       "        [38.942, 60.225, 39.117],\n",
       "        [   nan,    nan,    nan]],\n",
       "\n",
       "       [[35.319, 63.38 , 36.143],\n",
       "        [35.452, 64.002, 34.836],\n",
       "        [35.456, 62.881, 33.796],\n",
       "        ...,\n",
       "        [   nan,    nan,    nan],\n",
       "        [36.214, 69.041, 32.241],\n",
       "        [   nan,    nan,    nan]],\n",
       "\n",
       "       [[34.38 , 62.671, 33.056],\n",
       "        [34.421, 61.614, 32.055],\n",
       "        [35.18 , 62.107, 30.838],\n",
       "        ...,\n",
       "        [   nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan],\n",
       "        [34.553, 62.767, 29.969]]], dtype=float32), atom37_mask=array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False,  True, False],\n",
       "       [ True,  True,  True, ..., False,  True, False],\n",
       "       [ True,  True,  True, ..., False, False,  True]]), confidence=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b021b2-ed8c-4fcc-a93e-66772934bb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0224a21a-37c7-496f-a19e-e8892bb666bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We must pass zero vectors for input modalities with null\n",
    "\n",
    "# Dummy structure tokens\n",
    "dummy_structure_tokens = torch.zeros_like(seq_tokens_tensor, dtype=torch.int64, device=device)\n",
    "\n",
    "# Dummy tokens for ss8 (secondary structure, 11 classes) and SASA (solvent accessibility, 19 classes)\n",
    "dummy_ss8_tokens = torch.zeros_like(seq_tokens_tensor, dtype=torch.int64, device=device)\n",
    "dummy_sasa_tokens = torch.zeros_like(seq_tokens_tensor, dtype=torch.int64, device=device)\n",
    "\n",
    "# Dummy pLDDT values (typically float values per residue)\n",
    "dummy_average_plddt = torch.ones_like(seq_tokens_tensor, dtype=torch.float32, device=device)\n",
    "dummy_per_res_plddt = torch.ones_like(seq_tokens_tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "batch_size, seq_len = seq_tokens_tensor.shape\n",
    "dummy_rbf = torch.ones(batch_size, seq_len, 16,\n",
    "                       dtype=loaded_backbone_model.encoder.plddt_projection.weight.dtype,\n",
    "                       device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "157cc9ef-869a-4af9-9452-3d87006115f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence embeddings shape: torch.Size([1, 17, 1536])\n",
      "tensor([[[ 7.7637e-02, -1.7578e-02,  4.1016e-02,  ..., -2.9541e-02,\n",
      "          -1.9653e-02, -6.3324e-04],\n",
      "         [ 6.5308e-03,  2.5879e-02, -8.4473e-02,  ..., -3.1250e-02,\n",
      "          -8.1543e-02,  1.2500e-01],\n",
      "         [ 1.1035e-01, -8.0566e-02, -1.2061e-01,  ...,  6.2256e-02,\n",
      "          -2.2339e-02, -5.4688e-02],\n",
      "         ...,\n",
      "         [ 2.0599e-04,  1.5625e-01,  9.5703e-02,  ...,  1.1914e-01,\n",
      "          -4.3701e-02,  5.5664e-02],\n",
      "         [-3.1006e-02, -1.2451e-02,  2.6367e-01,  ..., -1.8164e-01,\n",
      "          -7.3242e-02,  2.2168e-01],\n",
      "         [ 5.9814e-02,  2.9907e-02,  1.7334e-02,  ..., -3.1250e-02,\n",
      "          -2.1729e-02, -1.6235e-02]]], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST SEQUENCE EMBEDDINGS\n",
    "with torch.no_grad():\n",
    "    embeddings = loaded_backbone_model.encoder.sequence_embed(seq_tokens_tensor)\n",
    "print(\"Sequence embeddings shape:\", embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4744f1a-9697-4206-95cb-89d745a599b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure tokens embedding shape: torch.Size([1, 17, 1536])\n",
      "tensor([[[ 0.0454,  0.1699,  0.1035,  ..., -0.1133, -0.0625,  0.0530],\n",
      "         [ 0.0454,  0.1699,  0.1035,  ..., -0.1133, -0.0625,  0.0530],\n",
      "         [ 0.0454,  0.1699,  0.1035,  ..., -0.1133, -0.0625,  0.0530],\n",
      "         ...,\n",
      "         [ 0.0454,  0.1699,  0.1035,  ..., -0.1133, -0.0625,  0.0530],\n",
      "         [ 0.0454,  0.1699,  0.1035,  ..., -0.1133, -0.0625,  0.0530],\n",
      "         [ 0.0454,  0.1699,  0.1035,  ..., -0.1133, -0.0625,  0.0530]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST STRUCTURE TOKENS EMBEDDINGS\n",
    "# Create dummy structure tokens (all zeros, matching the sequence shape)\n",
    "dummy_structure_tokens = torch.zeros_like(seq_tokens_tensor, dtype=torch.int64, device=device)\n",
    "with torch.no_grad():\n",
    "    structure_embedding = loaded_backbone_model.encoder.structure_tokens_embed(dummy_structure_tokens)\n",
    "print(\"Structure tokens embedding shape:\", structure_embedding.shape)\n",
    "print(structure_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3503f9b4-5f97-49b4-aa48-6ac7dff75000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pLDDT projection output shape: torch.Size([1, 17, 1536])\n",
      "tensor([[[ 1.0391,  0.9102, -0.0137,  ..., -0.2275, -1.1875,  1.2891],\n",
      "         [ 1.0391,  0.9102, -0.0137,  ..., -0.2275, -1.1875,  1.2891],\n",
      "         [ 1.0391,  0.9102, -0.0137,  ..., -0.2275, -1.1875,  1.2891],\n",
      "         ...,\n",
      "         [ 1.0391,  0.9102, -0.0137,  ..., -0.2275, -1.1875,  1.2891],\n",
      "         [ 1.0391,  0.9102, -0.0137,  ..., -0.2275, -1.1875,  1.2891],\n",
      "         [ 1.0391,  0.9102, -0.0137,  ..., -0.2275, -1.1875,  1.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST PLDDT PROJECTION\n",
    "# Create a dummy input for the pLDDT projection module (shape: batch_size x seq_len x 16)\n",
    "batch_size, seq_len = seq_tokens_tensor.shape\n",
    "dummy_rbf = torch.ones(\n",
    "    batch_size,\n",
    "    seq_len,\n",
    "    16,\n",
    "    dtype=loaded_backbone_model.encoder.plddt_projection.weight.dtype,\n",
    "    device=device\n",
    ")\n",
    "with torch.no_grad():\n",
    "    plddt_embedding = loaded_backbone_model.encoder.plddt_projection(dummy_rbf)\n",
    "print(\"pLDDT projection output shape:\", plddt_embedding.shape)\n",
    "print(plddt_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d14d1a37-adfe-4834-9f9b-93d30270e150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS8 embedding shape: torch.Size([1, 17, 1536])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST SS8 EMBEDDING\n",
    "# Create dummy tokens for SS8 (secondary structure; 11 classes)\n",
    "dummy_ss8_tokens = torch.zeros_like(seq_tokens_tensor, dtype=torch.int64, device=device)\n",
    "with torch.no_grad():\n",
    "    ss8_embedding = loaded_backbone_model.encoder.ss8_embed(dummy_ss8_tokens)\n",
    "print(\"SS8 embedding shape:\", ss8_embedding.shape)\n",
    "print(ss8_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b82b6f0-adea-4c4f-beab-c9cd038a7262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASA embedding shape: torch.Size([1, 17, 1536])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST SASA EMBEDDING\n",
    "# Create dummy tokens for SASA (solvent accessibility; 19 classes)\n",
    "dummy_sasa_tokens = torch.zeros_like(seq_tokens_tensor, dtype=torch.int64, device=device)\n",
    "with torch.no_grad():\n",
    "    sasa_embedding = loaded_backbone_model.encoder.sasa_embed(dummy_sasa_tokens)\n",
    "print(\"SASA embedding shape:\", sasa_embedding.shape)\n",
    "print(sasa_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "952e2100-79ce-4625-82bb-deddb5ed8508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function embedding 0 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2812,  0.1147, -0.4746,  ...,  0.1230, -0.6133,  0.3711],\n",
      "         [-0.9922, -0.3828,  0.4082,  ...,  0.4238, -0.2676,  0.6367],\n",
      "         ...,\n",
      "         [-0.3105,  0.6406, -0.7344,  ..., -0.4609,  0.2061,  0.7539],\n",
      "         [-0.1162, -0.0476,  0.5820,  ..., -0.3125, -0.2734, -0.3555],\n",
      "         [-0.2480,  0.2949, -0.6211,  ...,  0.3691,  0.1768, -0.2119]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 1 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.3535, -0.1108,  0.1235,  ...,  0.5859,  0.1719, -0.1631],\n",
      "         [ 0.0452,  0.4883, -0.4570,  ...,  0.4160, -0.3770, -0.2305],\n",
      "         ...,\n",
      "         [ 0.9102,  0.6133,  0.3770,  ...,  0.2148,  0.0776, -1.0000],\n",
      "         [-0.6211,  0.0542, -0.7031,  ..., -0.0571, -0.3672,  0.0087],\n",
      "         [-0.1553, -0.3516,  0.2656,  ...,  0.4727, -0.4297,  0.5312]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 2 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.4531, -0.0102,  0.4590,  ..., -0.8711,  0.7344, -1.1094],\n",
      "         [-0.6250,  0.4199,  0.4570,  ..., -0.6328,  0.7617,  0.5312],\n",
      "         ...,\n",
      "         [-0.0391,  0.3457,  0.4902,  ..., -0.8984, -0.1045,  0.5547],\n",
      "         [-0.5781,  0.3184,  0.5234,  ...,  0.9688,  0.8867,  0.6250],\n",
      "         [ 0.1553, -0.4785, -0.5234,  ...,  0.0718, -0.6875,  0.1904]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 3 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-4.0430e-01,  4.6680e-01, -9.8438e-01,  ...,  9.1309e-02,\n",
      "          -4.1797e-01,  1.0000e+00],\n",
      "         [-8.3984e-01,  8.6328e-01,  7.1484e-01,  ..., -2.7734e-01,\n",
      "           6.3281e-01, -4.9023e-01],\n",
      "         ...,\n",
      "         [ 1.4922e+00,  3.7891e-01,  5.7422e-01,  ...,  5.1562e-01,\n",
      "           6.5234e-01,  6.9922e-01],\n",
      "         [ 1.8359e-01, -2.0605e-01, -8.9844e-01,  ...,  8.5547e-01,\n",
      "           1.0938e+00,  9.4922e-01],\n",
      "         [-5.8594e-01, -5.3516e-01, -4.8065e-04,  ...,  4.2578e-01,\n",
      "          -2.2949e-02, -1.8457e-01]]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 4 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1865, -0.1445, -0.0466,  ...,  0.7305, -0.2305,  0.0398],\n",
      "         [ 0.7422, -0.2539, -0.7109,  ..., -0.4277,  0.0864,  0.0147],\n",
      "         ...,\n",
      "         [ 0.8594, -0.6523, -0.5430,  ..., -0.0913, -0.8555, -0.7109],\n",
      "         [ 0.0298, -0.3926,  0.3848,  ...,  0.0820, -1.6250,  0.3477],\n",
      "         [-0.4180, -0.5469,  0.0747,  ..., -0.0757, -0.2598, -0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 5 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0262, -0.4414,  0.5273,  ..., -0.4590, -1.1328, -1.3594],\n",
      "         [ 0.1348,  0.1602, -0.6836,  ..., -0.6211,  0.6445,  0.6758],\n",
      "         ...,\n",
      "         [-1.5078,  0.7344,  0.3887,  ..., -0.2461,  0.1177,  0.4180],\n",
      "         [ 0.8594, -0.1289, -0.5430,  ...,  0.6055, -0.1797,  0.0349],\n",
      "         [ 0.7344, -0.0718,  0.2129,  ..., -0.4023, -0.5469, -0.6719]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 6 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2227,  0.2617, -0.4082,  ..., -0.4434, -0.4023,  0.1816],\n",
      "         [ 0.0645,  0.4668,  0.0231,  ...,  0.5117, -0.9453,  0.3086],\n",
      "         ...,\n",
      "         [ 1.2188,  0.0977,  0.3516,  ...,  0.2070,  0.6641, -0.4258],\n",
      "         [-0.5625,  0.8008,  0.5508,  ...,  0.1177, -1.2734,  0.3281],\n",
      "         [-0.4102, -0.1621, -0.7422,  ...,  0.3301, -0.0659, -0.5586]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Function embedding 7 shape: torch.Size([1, 17, 192])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2930, -0.6172, -0.0393,  ...,  0.4434, -0.2715,  0.1377],\n",
      "         [ 0.0162, -0.6680,  0.3809,  ..., -0.9297,  0.1543, -0.1641],\n",
      "         ...,\n",
      "         [ 0.5859,  0.3535,  0.3770,  ...,  0.7344, -0.2412, -0.5352],\n",
      "         [ 0.0500,  0.6602,  0.3125,  ..., -0.6484,  0.7461,  1.1641],\n",
      "         [ 0.0258,  0.4141,  0.5547,  ..., -0.3711,  0.2393,  0.1494]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST FUNCTION EMBEDDINGS\n",
    "# The function_embed module is a ModuleList; test each embedding layer.\n",
    "for i, func_embed in enumerate(loaded_backbone_model.encoder.function_embed):\n",
    "    with torch.no_grad():\n",
    "        func_embedding = func_embed(seq_tokens_tensor)\n",
    "    print(f\"Function embedding {i} shape:\", func_embedding.shape)\n",
    "    print(func_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bec9f833-0d3e-42fe-9921-af5ddbe50215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue embedding shape: torch.Size([1, 1536])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# TEST RESIDUE EMBEDDING\n",
    "# The residue embedding is an EmbeddingBag, so we flatten the input and provide offsets.\n",
    "dummy_residue_tokens = torch.zeros(seq_tokens_tensor.shape, dtype=torch.int64, device=device)\n",
    "dummy_residue_tokens_flat = dummy_residue_tokens.view(-1)\n",
    "offsets = torch.tensor([0], dtype=torch.int64, device=device)\n",
    "with torch.no_grad():\n",
    "    residue_embedding = loaded_backbone_model.encoder.residue_embed(dummy_residue_tokens_flat, offsets)\n",
    "print(\"Residue embedding shape:\", residue_embedding.shape)\n",
    "print(residue_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a4d468-33d2-4402-8891-ee650670af46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3ea49-1520-46af-9098-08f1331bd841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd7911-f879-4c02-ac8c-7ac00d3c301d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c09042-5d18-480b-80bf-4827fac91ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca8e40-53bf-43bd-965b-8a7a19af6e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b243f8-8211-491d-93d9-b7ca7097e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42da637-1ff1-44c7-927e-f27afb717393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ae2f7-1991-48b4-a8c9-53906eddbe2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "416b0071-24a0-43c2-901e-190dbbdd95db",
   "metadata": {
    "tags": []
   },
   "source": [
    "structure_embedding = loaded_backbone_model.encoder.structure_tokens_embed(structure_tokens)\n",
    "print(\"Structure tokens embedding shape:\", structure_embedding.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b9f67-f5c4-4b43-a90a-1ecd27aeb6fe",
   "metadata": {},
   "source": [
    "# objectives:\n",
    "# 1. validate other embeddings work (may need antibody pdbs as input)\n",
    "# 2. validate embedding dimensions / shape\n",
    "# 3. Run multiple sequences in one pass?\n",
    "# 4. Speed test 10, 100, 1000 sequences runtime\n",
    "# 5. Training...OPT 3 guide a fine-tuning of this model (on 5 random antibody sequences)\n",
    "# 6. LORA for training econo.y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d1ebe-6438-490b-b6ed-fcb0f5c3213c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9c9a7-6aa2-4bdb-a3ee-21dced1e13a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
